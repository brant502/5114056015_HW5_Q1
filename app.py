import streamlit as st
from transformers import pipeline

# Use a cache to load the model only once, which speeds up the app after the first run.
@st.cache_resource
def get_model():
    """
    Loads and returns a pre-trained text classification model from Hugging Face.
    This model is specifically trained to detect text generated by OpenAI's models.
    """
    return pipeline("text-classification", model="roberta-base-openai-detector")

# --- UI Configuration ---
st.set_page_config(page_title="AI Text Detector", page_icon="ğŸ¤–")

# --- Main Application ---

# 1. Set up the user interface
st.title("AI / Human æ–‡ç« åµæ¸¬å™¨ (AI Detector)")
st.markdown(
    """
    è¼¸å…¥ä¸€æ®µæ–‡æœ¬ï¼Œç„¶å¾Œé»æ“Šâ€œåˆ†ææ–‡æœ¬â€æŒ‰éˆ•ï¼Œæ¨¡å‹å°‡æœƒåˆ¤æ–·è©²æ–‡æœ¬ç”± AI ç”Ÿæˆæˆ–ç”±äººé¡æ’°å¯«çš„æ©Ÿç‡ã€‚
    \n*(Enter a piece of text and click the 'Analyze Text' button. The model will predict the probability of it being AI-generated or human-written.)*
    """
)

# Create a text area for user input
text_input = st.text_area(
    "åœ¨æ­¤è™•è²¼ä¸Šæ–‡æœ¬ (Paste your text here)",
    height=250,
    placeholder="Enter text to analyze...",
)

# Create a button to trigger the analysis
if st.button("åˆ†ææ–‡æœ¬ (Analyze Text)"):
    if text_input:
        # Show a spinner while the model is working
        with st.spinner("åˆ†æä¸­... (Analyzing...)"):
            # 2. Load the model
            # The first time this is called, it will download and cache the model.
            # Subsequent calls will use the cached model.
            classifier = get_model()

            # 3. Perform prediction on the user's text
            # The model returns a list containing a dictionary, e.g., [{'label': 'Real', 'score': 0.99}]
            results = classifier(text_input)

            # 4. Process the model's output
            score = results[0]["score"]
            label = results[0]["label"]

            # The 'roberta-base-openai-detector' model uses 'Real' for Human and 'Fake' for AI.
            # We assign the probabilities based on the label.
            if label == "Real":
                human_prob = score
                ai_prob = 1 - score
            else:  # label == 'Fake'
                ai_prob = score
                human_prob = 1 - score

            # 5. Display the results
            st.subheader("åˆ†æçµæœ (Analysis Result)")

            # Determine the final verdict
            verdict = "ğŸ¤– é€™æ®µæ–‡å­—å¾ˆå¯èƒ½æ˜¯ **AI ç”Ÿæˆ** çš„ã€‚" if ai_prob > human_prob else "ğŸ§‘â€ğŸ’» é€™æ®µæ–‡å­—å¾ˆå¯èƒ½æ˜¯ **äººé¡æ’°å¯«** çš„ã€‚"
            st.markdown(f"### {verdict}")

            # Display metrics in columns
            col1, col2 = st.columns(2)
            with col1:
                st.metric(label="ğŸ§‘â€ğŸ’» Human", value=f"{human_prob:.2%}")
            with col2:
                st.metric(label="ğŸ¤– AI", value=f"{ai_prob:.2%}")

            # Show a progress bar to visualize the AI probability
            st.progress(ai_prob, text=f"AI ç”Ÿæˆæ©Ÿç‡: {ai_prob:.2%}")

    else:
        # Show a warning if the user clicks the button without entering text
        st.warning("è«‹è¼¸å…¥ä¸€äº›æ–‡æœ¬é€²è¡Œåˆ†æã€‚ (Please enter some text to analyze.)")

# Add a footer with a link to the reference UI
